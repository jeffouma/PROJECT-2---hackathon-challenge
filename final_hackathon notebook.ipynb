{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HACKATHON CHALLENGE","metadata":{}},{"cell_type":"markdown","source":"Will start by importing the neccessary packages that will be used for the data processing.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:07.001050Z","iopub.execute_input":"2022-06-26T14:05:07.001772Z","iopub.status.idle":"2022-06-26T14:05:07.031406Z","shell.execute_reply.started":"2022-06-26T14:05:07.001683Z","shell.execute_reply":"2022-06-26T14:05:07.030256Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom string import punctuation\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:07.099423Z","iopub.execute_input":"2022-06-26T14:05:07.099810Z","iopub.status.idle":"2022-06-26T14:05:08.603873Z","shell.execute_reply.started":"2022-06-26T14:05:07.099775Z","shell.execute_reply":"2022-06-26T14:05:08.602860Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2022/train_set.csv')\ntest = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2022/test_set.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:08.605778Z","iopub.execute_input":"2022-06-26T14:05:08.606080Z","iopub.status.idle":"2022-06-26T14:05:08.895645Z","shell.execute_reply.started":"2022-06-26T14:05:08.606055Z","shell.execute_reply":"2022-06-26T14:05:08.894625Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:48:04.298740Z","iopub.execute_input":"2022-06-26T08:48:04.299552Z","iopub.status.idle":"2022-06-26T08:48:04.304299Z","shell.execute_reply.started":"2022-06-26T08:48:04.299514Z","shell.execute_reply":"2022-06-26T08:48:04.303174Z"}}},{"cell_type":"markdown","source":"**Exploratory data analysis** is a crucial process in Data analysis that enables us to gain insights into the data. We try to understand the data in details before pre-processing. ","metadata":{}},{"cell_type":"code","source":"#lets preview both the test and train data\nprint(f'shape == {train.shape}')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:08.896859Z","iopub.execute_input":"2022-06-26T14:05:08.897575Z","iopub.status.idle":"2022-06-26T14:05:08.929450Z","shell.execute_reply.started":"2022-06-26T14:05:08.897538Z","shell.execute_reply":"2022-06-26T14:05:08.928462Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#lets preview the first 5 entries of the test data\nprint(f'shape == {test.shape}')\ntest.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:08.935343Z","iopub.execute_input":"2022-06-26T14:05:08.938582Z","iopub.status.idle":"2022-06-26T14:05:08.948782Z","shell.execute_reply.started":"2022-06-26T14:05:08.938545Z","shell.execute_reply":"2022-06-26T14:05:08.947755Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#lets see our unique y variable\nlanguages = list(np.unique(np.array(train.lang_id.to_list())))\nlanguages","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:08.950477Z","iopub.execute_input":"2022-06-26T14:05:08.951223Z","iopub.status.idle":"2022-06-26T14:05:08.974452Z","shell.execute_reply.started":"2022-06-26T14:05:08.951184Z","shell.execute_reply":"2022-06-26T14:05:08.973544Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"It looks like we have 11 unique languages that will train our model on","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:23:33.876067Z","iopub.execute_input":"2022-06-26T09:23:33.876537Z","iopub.status.idle":"2022-06-26T09:23:33.886075Z","shell.execute_reply.started":"2022-06-26T09:23:33.876501Z","shell.execute_reply":"2022-06-26T09:23:33.883926Z"}}},{"cell_type":"code","source":"#wec then check how our y variable is distributed among the 11 languages\ntotal_dist = train.groupby(by = 'lang_id').count()\ntotal_dist","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:08.975720Z","iopub.execute_input":"2022-06-26T14:05:08.976057Z","iopub.status.idle":"2022-06-26T14:05:09.000563Z","shell.execute_reply.started":"2022-06-26T14:05:08.976024Z","shell.execute_reply":"2022-06-26T14:05:08.999556Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"So its true that our we wont need any upsampling or downsampling staff as our data is normally distributed among the 11 languages","metadata":{}},{"cell_type":"code","source":"#we plot a line graph with the count of languages on y axis\ntotal_dist.plot()\nplt.title('line graph showing count of languages')\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:09.002075Z","iopub.execute_input":"2022-06-26T14:05:09.002519Z","iopub.status.idle":"2022-06-26T14:05:09.214041Z","shell.execute_reply.started":"2022-06-26T14:05:09.002466Z","shell.execute_reply":"2022-06-26T14:05:09.213155Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plt.pie(total_dist.text, labels = total_dist.index)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:09.215516Z","iopub.execute_input":"2022-06-26T14:05:09.215842Z","iopub.status.idle":"2022-06-26T14:05:09.340806Z","shell.execute_reply.started":"2022-06-26T14:05:09.215809Z","shell.execute_reply":"2022-06-26T14:05:09.339753Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"From the above two graphs, we can tell that our data in normally distributed","metadata":{}},{"cell_type":"code","source":"#we then print the first few information of our training set\nfor i in train.index:\n    if i < 5:\n        print(train.loc[i].text)\n   \n    elif i >32995:\n        print(train.loc[i].text)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:09.342264Z","iopub.execute_input":"2022-06-26T14:05:09.342625Z","iopub.status.idle":"2022-06-26T14:05:09.364667Z","shell.execute_reply.started":"2022-06-26T14:05:09.342582Z","shell.execute_reply":"2022-06-26T14:05:09.358202Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Lets have a look at the test data","metadata":{}},{"cell_type":"code","source":"#we preview the first 20 elements on the text entries\ntest.head(20).text.to_list()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:09.370449Z","iopub.execute_input":"2022-06-26T14:05:09.370974Z","iopub.status.idle":"2022-06-26T14:05:09.379655Z","shell.execute_reply.started":"2022-06-26T14:05:09.370938Z","shell.execute_reply":"2022-06-26T14:05:09.378533Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"From the above data We can note the following:\n> 1. There are punctuations to be dealt with here\n> 2. There is a unique tag (<fn>) That needs special attention","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:11:32.025646Z","iopub.execute_input":"2022-06-26T10:11:32.026157Z","iopub.status.idle":"2022-06-26T10:11:32.032910Z","shell.execute_reply.started":"2022-06-26T10:11:32.026120Z","shell.execute_reply":"2022-06-26T10:11:32.031781Z"}}},{"cell_type":"code","source":"#We collent the entries having fn tags for analysis\nhave_fn = []\nfor i in test.index:\n    txt = test.loc[i].text\n    if '<fn>' in txt:\n        have_fn.append(txt)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:09.381288Z","iopub.execute_input":"2022-06-26T14:05:09.381805Z","iopub.status.idle":"2022-06-26T14:05:10.265002Z","shell.execute_reply.started":"2022-06-26T14:05:09.381753Z","shell.execute_reply":"2022-06-26T14:05:10.264008Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#lets print the first two of those special cases\nhave_fn[:2]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:10.266376Z","iopub.execute_input":"2022-06-26T14:05:10.266908Z","iopub.status.idle":"2022-06-26T14:05:10.273970Z","shell.execute_reply.started":"2022-06-26T14:05:10.266863Z","shell.execute_reply":"2022-06-26T14:05:10.272547Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#how many of those special cases are available\nfn_total = len(have_fn)\nfn_total","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:10.275718Z","iopub.execute_input":"2022-06-26T14:05:10.276558Z","iopub.status.idle":"2022-06-26T14:05:10.287021Z","shell.execute_reply.started":"2022-06-26T14:05:10.276524Z","shell.execute_reply":"2022-06-26T14:05:10.285937Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_total = test.shape[0]\nlabels = ['have fn tag','lack fn tag']\nvalues = [fn_total,(test_total-fn_total)]\nplt.pie(values, labels=labels, colors = ['red','green'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:10.288702Z","iopub.execute_input":"2022-06-26T14:05:10.289481Z","iopub.status.idle":"2022-06-26T14:05:10.403926Z","shell.execute_reply.started":"2022-06-26T14:05:10.289444Z","shell.execute_reply":"2022-06-26T14:05:10.402837Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#lets get the fn total percentage\nfail_percentage = np.round((fn_total/test_total)*100,2)\nfail_percentage","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:10.408343Z","iopub.execute_input":"2022-06-26T14:05:10.411228Z","iopub.status.idle":"2022-06-26T14:05:10.423816Z","shell.execute_reply.started":"2022-06-26T14:05:10.411187Z","shell.execute_reply":"2022-06-26T14:05:10.422547Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"We have 1.9 percent of our data having fn tags. This implies that our model will havean f1 score of 98.1% maximum.\nTo solve that kind of problem, will pass our test data through a funtion which will separate the entries with <fn> tag with those lacking the tag.\n\nWill then handle those with the <fn> tag with special considerations","metadata":{}},{"cell_type":"markdown","source":"##### ","metadata":{}},{"cell_type":"markdown","source":"# FEATURE ENGENEERING","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:27:32.176579Z","iopub.execute_input":"2022-06-26T10:27:32.177118Z","iopub.status.idle":"2022-06-26T10:27:32.183658Z","shell.execute_reply.started":"2022-06-26T10:27:32.177083Z","shell.execute_reply":"2022-06-26T10:27:32.182428Z"}}},{"cell_type":"markdown","source":"We create a funtion called train_processing to process our train data before feeding it into the model","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:30:29.986146Z","iopub.execute_input":"2022-06-26T10:30:29.986685Z","iopub.status.idle":"2022-06-26T10:30:29.995873Z","shell.execute_reply.started":"2022-06-26T10:30:29.986649Z","shell.execute_reply":"2022-06-26T10:30:29.993833Z"}}},{"cell_type":"code","source":"def train_preprocessing(text):\n    \n    '''\n    This functions cleans text from line breaks, URLs, numbers, etc.\n    ''' \n    \n    text = text.replace(',','')\n    text = text.replace('.',' ')\n    text = text.lower() #to lower case\n    text = text.replace('\\n', ' ') # remove line breaks\n    text = text.replace('\\@(\\w*)', '') # remove mentions\n    text = re.sub(r\"\\bhttps://t.co/\\w+\", '', text) # remove URLs\n    text = re.sub(r'\\#', '', text) # remove hashtags. To remove full hashtag: '\\#(\\w*)'\n    text = re.sub(' +', ' ', text) # remove 1+ spaces\n    text = re.sub(\"\\n\",\" \",text)\n    text =' '.join(text.split())\n\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:10.428836Z","iopub.execute_input":"2022-06-26T14:05:10.429508Z","iopub.status.idle":"2022-06-26T14:05:10.443674Z","shell.execute_reply.started":"2022-06-26T14:05:10.429453Z","shell.execute_reply":"2022-06-26T14:05:10.442550Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#we then apply the text processing to our train data\ntrain['text'] = train['text'].apply(train_preprocessing)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:10.450514Z","iopub.execute_input":"2022-06-26T14:05:10.453331Z","iopub.status.idle":"2022-06-26T14:05:11.438911Z","shell.execute_reply.started":"2022-06-26T14:05:10.453287Z","shell.execute_reply":"2022-06-26T14:05:11.437941Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#we devide our features into the x and y as follows\nX = train['text']\ny = train['lang_id']","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:11.440431Z","iopub.execute_input":"2022-06-26T14:05:11.440798Z","iopub.status.idle":"2022-06-26T14:05:11.446844Z","shell.execute_reply.started":"2022-06-26T14:05:11.440763Z","shell.execute_reply":"2022-06-26T14:05:11.445686Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"##### ","metadata":{}},{"cell_type":"markdown","source":"# MODEL BUILDING","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:33:08.779726Z","iopub.execute_input":"2022-06-26T10:33:08.780322Z","iopub.status.idle":"2022-06-26T10:33:08.787969Z","shell.execute_reply.started":"2022-06-26T10:33:08.780289Z","shell.execute_reply":"2022-06-26T10:33:08.785864Z"}}},{"cell_type":"markdown","source":"Will use train test split to devide our data into training and testing set. Will the try multiple models and then pick the one performing best on the testing data","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:34:28.790138Z","iopub.execute_input":"2022-06-26T10:34:28.790697Z","iopub.status.idle":"2022-06-26T10:34:28.799027Z","shell.execute_reply.started":"2022-06-26T10:34:28.790660Z","shell.execute_reply":"2022-06-26T10:34:28.797517Z"}}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:11.448647Z","iopub.execute_input":"2022-06-26T14:05:11.448896Z","iopub.status.idle":"2022-06-26T14:05:11.460838Z","shell.execute_reply.started":"2022-06-26T14:05:11.448874Z","shell.execute_reply":"2022-06-26T14:05:11.459975Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### MultinomialNB(Best model for this data set)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:09:42.030879Z","iopub.execute_input":"2022-06-26T11:09:42.031498Z","iopub.status.idle":"2022-06-26T11:09:42.041069Z","shell.execute_reply.started":"2022-06-26T11:09:42.031446Z","shell.execute_reply":"2022-06-26T11:09:42.038340Z"}}},{"cell_type":"markdown","source":"Will strart with the model of intrest aka MultinomialNB Then will also check other models and see how they also performs","metadata":{}},{"cell_type":"code","source":"# Creating a pipeline for the gridsearch\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'alpha': [0.047]}  # setting parameter grid\n\ntuned_mnb = Pipeline([('tfidf', TfidfVectorizer(\n                                                max_df=0.9,ngram_range=(1, 5), analyzer= 'char'\n                                               )),\n                      ('mnb', GridSearchCV(MultinomialNB(),\n                                           param_grid=param_grid,\n                                           cv=5,\n                                           scoring='f1_weighted'))\n                      ])\n\ntuned_mnb.fit(X_train, y_train)  # Fitting the model\n\ny_pred_mnb = tuned_mnb.predict(X_val)  # predicting the fit on validation set\n\nprint(classification_report(y_val, y_pred_mnb))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:11.462116Z","iopub.execute_input":"2022-06-26T14:05:11.462804Z","iopub.status.idle":"2022-06-26T14:05:42.101419Z","shell.execute_reply.started":"2022-06-26T14:05:11.462769Z","shell.execute_reply":"2022-06-26T14:05:42.100395Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Other models","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:10:04.390936Z","iopub.execute_input":"2022-06-26T11:10:04.391291Z","iopub.status.idle":"2022-06-26T11:10:04.397906Z","shell.execute_reply.started":"2022-06-26T11:10:04.391262Z","shell.execute_reply":"2022-06-26T11:10:04.396321Z"}}},{"cell_type":"code","source":"# Random Forest Classifier\nrf = Pipeline([('tfidf', TfidfVectorizer(max_df=0.9,min_df = 2,ngram_range=(1, 1), analyzer= 'word')),\n               ('clf', RandomForestClassifier(max_depth=100, \n                                              n_estimators=100))])\n\n# Naïve Bayes:\nnb = Pipeline([('tfidf', TfidfVectorizer(max_df=0.9,min_df = 2,ngram_range=(1, 1), analyzer= 'word')),\n               ('clf', MultinomialNB())])\n\n# K-NN Classifier\nknn = Pipeline([('tfidf', TfidfVectorizer(max_df=0.9,min_df = 2,ngram_range=(1, 1), analyzer= 'word')),\n                ('clf', KNeighborsClassifier(n_neighbors=5,  \n                                             p=2))])\n\n# Logistic Regression\nlr = Pipeline([('tfidf',TfidfVectorizer(max_df=0.9,min_df = 2,ngram_range=(1, 1), analyzer= 'word')),\n               ('clf',LogisticRegression(C=1,  \n                                         max_iter=1000))])\n# Linear SVC:\nlsvc = Pipeline([('tfidf', TfidfVectorizer(max_df=0.9,min_df = 2,ngram_range=(1, 1), analyzer= 'word')),\n                 ('clf', LinearSVC())])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:42.102972Z","iopub.execute_input":"2022-06-26T14:05:42.103574Z","iopub.status.idle":"2022-06-26T14:05:42.114870Z","shell.execute_reply.started":"2022-06-26T14:05:42.103537Z","shell.execute_reply":"2022-06-26T14:05:42.113193Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Fiting other models ","metadata":{}},{"cell_type":"code","source":"# Random forest \nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_val)\n\n# Niave bayes\nnb.fit(X_train, y_train)\ny_pred_nb = nb.predict(X_val)\n\n# K - nearest neighbors\nknn.fit(X_train, y_train)\ny_pred_knn = knn.predict(X_val)\n\n# Linear regression\nlr.fit(X_train, y_train)\ny_pred_lr = lr.predict(X_val)\n\n# Linear SVC\nlsvc.fit(X_train, y_train)\ny_pred_lsvc = lsvc.predict(X_val)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:05:42.116342Z","iopub.execute_input":"2022-06-26T14:05:42.116692Z","iopub.status.idle":"2022-06-26T14:06:41.177326Z","shell.execute_reply.started":"2022-06-26T14:05:42.116658Z","shell.execute_reply":"2022-06-26T14:06:41.176344Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print('Random forest classifier')\nprint(classification_report(y_val, y_pred_rf))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:06:41.178623Z","iopub.execute_input":"2022-06-26T14:06:41.179209Z","iopub.status.idle":"2022-06-26T14:06:41.202283Z","shell.execute_reply.started":"2022-06-26T14:06:41.179169Z","shell.execute_reply":"2022-06-26T14:06:41.201271Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print('Naive Bayes classifier')\nprint(classification_report(y_val, y_pred_nb))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:06:41.203664Z","iopub.execute_input":"2022-06-26T14:06:41.204435Z","iopub.status.idle":"2022-06-26T14:06:41.221981Z","shell.execute_reply.started":"2022-06-26T14:06:41.204400Z","shell.execute_reply":"2022-06-26T14:06:41.221033Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print('K-Nearest Neighbours classifier')\nprint(classification_report(y_val, y_pred_knn))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:06:41.223385Z","iopub.execute_input":"2022-06-26T14:06:41.223745Z","iopub.status.idle":"2022-06-26T14:06:41.246839Z","shell.execute_reply.started":"2022-06-26T14:06:41.223710Z","shell.execute_reply":"2022-06-26T14:06:41.245838Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print('Logistic linear Regression')\nprint(classification_report(y_val, y_pred_lr))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:06:41.248248Z","iopub.execute_input":"2022-06-26T14:06:41.248665Z","iopub.status.idle":"2022-06-26T14:06:41.270534Z","shell.execute_reply.started":"2022-06-26T14:06:41.248632Z","shell.execute_reply":"2022-06-26T14:06:41.269532Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print('Linear SVC')\nprint(classification_report(y_val, y_pred_lsvc))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:06:41.271773Z","iopub.execute_input":"2022-06-26T14:06:41.272186Z","iopub.status.idle":"2022-06-26T14:06:41.293360Z","shell.execute_reply.started":"2022-06-26T14:06:41.272151Z","shell.execute_reply":"2022-06-26T14:06:41.292356Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Conclussion","metadata":{}},{"cell_type":"markdown","source":"Even Though MultinomialNB is the best model of choice, Other models when properly tuned can also perform absolutely well","metadata":{}},{"cell_type":"markdown","source":"# Kaggle submission","metadata":{}},{"cell_type":"markdown","source":"****We wont just call .predict on our test data but rather, will do the following:\n> 1. Will clean our test data\n> 2. Will create a funtion to separate the the special case ie <fn> with the non-special case\n> 3. Will create a funtion to predict the special case and will use  .predict to predict the non-special case","metadata":{}},{"cell_type":"markdown","source":"We create a function called find_k which will deal with the speacial cases of our test data","metadata":{}},{"cell_type":"code","source":"def find_k(m):\n    if '.en.' in m:\n        k = 'eng'\n    elif '.af.' in m:\n        k = 'afr'\n    elif 'tso_' in m:\n        k = 'tso'\n    elif '.xh.' in m:\n        k = 'xho'\n    elif '_Xho' in m:\n        k = 'xho'\n    elif 'Venda.' in m:\n        k = 'ven'\n    elif 'ndebele' in m.lower():\n        k = 'nbl'\n    elif 'sesotho' in m.lower():\n        k = 'sot'\n    elif 'sepedi' in m.lower():\n        k = 'nso'\n    elif 'zulu' in m.lower():\n        k = 'zul'\n    elif 'isiZulu.' in m:\n        k = 'zul'\n    elif 'isiXhosa.' in m:\n        k = 'xho'\n    elif 'Tshivenda' in m:\n        k = 'ven'\n    elif 'Xhosa' in m:\n        k = 'xho'\n    else:\n        value = tuned_mnb.predict([train_preprocessing(m)])\n        value = str(value)[2:5]\n        k = value\n\n    return k","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:10:04.239612Z","iopub.execute_input":"2022-06-26T14:10:04.240615Z","iopub.status.idle":"2022-06-26T14:10:04.249070Z","shell.execute_reply.started":"2022-06-26T14:10:04.240569Z","shell.execute_reply":"2022-06-26T14:10:04.247849Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def predict_test(data):\n    if '<fn>' in data:\n        value = find_k(data)\n    else:\n        value = tuned_mnb.predict([train_preprocessing(data)])\n        value = str(value)[2:5]\n        \n    return value","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:10:23.372903Z","iopub.execute_input":"2022-06-26T14:10:23.373791Z","iopub.status.idle":"2022-06-26T14:10:23.378414Z","shell.execute_reply.started":"2022-06-26T14:10:23.373753Z","shell.execute_reply":"2022-06-26T14:10:23.377539Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"We allow every x values to pass through the filter above ie prediction test which will sepate the special cases data with the normal data which our model can handle directly.","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in test.index:\n    txt = test.loc[i].text\n    predictions.append(predict_test(txt))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:10:26.544205Z","iopub.execute_input":"2022-06-26T14:10:26.544571Z","iopub.status.idle":"2022-06-26T14:11:22.382883Z","shell.execute_reply.started":"2022-06-26T14:10:26.544539Z","shell.execute_reply":"2022-06-26T14:11:22.381634Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"We then create a csv file containing our predictions","metadata":{}},{"cell_type":"code","source":"# test['text'] = test['text'].apply(train_preprocessing)\nsubmission_trial = pd.DataFrame(test['index'])\nsubmission_trial['lang_id'] = predictions\nsubmission_trial.to_csv('zf.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:11:28.745113Z","iopub.execute_input":"2022-06-26T14:11:28.745452Z","iopub.status.idle":"2022-06-26T14:11:28.764839Z","shell.execute_reply.started":"2022-06-26T14:11:28.745423Z","shell.execute_reply":"2022-06-26T14:11:28.763901Z"},"trusted":true},"execution_count":39,"outputs":[]}]}